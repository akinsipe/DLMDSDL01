{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Network in Keras\n",
    "\n",
    "Convolutional neural networks (CNN) play an important part in modern machine learning applications as they allow to analyse a wide range of data such as images or text automatically. CNNs are used to detect features of the data automatically, for example if an image is analysed by a CNN, it can be trained to tell cats apart from dogs.\n",
    "\n",
    "A widely known practice dataset for image recognition is the MNIST dataset The data contain a large number of handwritten digits in the range 0...9 and the task focuses on recognizing the images. The task was pioneered by Yann LeCun and others in 1998 ([original paper](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf) [Yann LeCun's Webpage for MNIST](http://yann.lecun.com/exdb/lenet/)). \n",
    "\n",
    "The images are snipplets of 28 pixels x 28 pixels = 784 pixels and there are n=10 digits to recognise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import datetime as dt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%pylab inline\n",
    "# large figures\n",
    "rcParams['figure.figsize'] = 8, 6\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "As this is a popular dataset to get to know CNNs, the data are available as part of TensorFlow:\n",
    "\n",
    "There are 6,000 images avaiable, each with a size of 28x28 pixels.\n",
    "The \"shape\" of the dataset is therefore $(28,28)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 1234\n",
    "print('True label: {}'.format(y_train[index]) )\n",
    "plt.imshow(x_train[index], cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we make the shape of the input tensor we will use in our model explicit:\n",
    " * length of the trainings and test tensor\n",
    " * 28x28 pixels\n",
    " * grayscale (1 colour)\n",
    "\n",
    "We also need to normalise the colour range by dividing by 255 (RGB range).\n",
    "In addition, we cast the values to floating point nubmers with 32 bit accuracy so they all have a well defined state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape of input tensor (60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')\n",
    "\n",
    "\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "\n",
    "print('Final shape of input tensor {}'.format(x_train.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Simple model\n",
    "\n",
    "We start with a very simple model that has only one convloutional layer.\n",
    "We then add one fully connected (or dense) layer with ReLU activation function \n",
    "and then use a fully connected layer with 10 nodes (one for each digit in $0,\\ldots,9$)\n",
    "with softmax activation. The latter converts the output of the nodes into a probability.\n",
    "\n",
    "We also add a dropout layer after the first fully connected layer to regularize the network.\n",
    "Using the Keras interface, the model is then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               692352    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 693,962\n",
      "Trainable params: 693,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, \n",
    "                                 kernel_size=(3,3), \n",
    "                                 strides=(1,1),\n",
    "                                 padding='valid',\n",
    "                                 activation='relu', \n",
    "                                 input_shape=(28,28,1)))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# flatten the 2D convolution layers before adding a fully connected (dense) layer\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
    "\n",
    "#add dropout for regularisation\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "# final fully connected (dense) layer which returns a probability for each of the digits 0...9\n",
    "model.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this simple model has already almost 700,000 free parameters (network weights) that need to be optimized.\n",
    "\n",
    "We now specify how we train the network.\n",
    "We need to specify the optimizer used during training. Several choices exist, as a good practice, the Adam Optimizer (See the [paper](https://arxiv.org/abs/1412.6980) and the [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) for more details) is a good starting point.\n",
    "\n",
    "We also use cross-entropy for the loss function as this is a classification problem.\n",
    "\n",
    "Furthermore, we add the accuracy as the metric we want to monitor during network training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then train the model by calling ```model.fit()``` using 5 epochs to complete the training quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 31s 513us/sample - loss: 1.6547 - sparse_categorical_accuracy: 0.8061\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 30s 506us/sample - loss: 1.5884 - sparse_categorical_accuracy: 0.8725\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 29s 478us/sample - loss: 1.5851 - sparse_categorical_accuracy: 0.8759\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 28s 473us/sample - loss: 1.5836 - sparse_categorical_accuracy: 0.8774\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 32s 537us/sample - loss: 1.5895 - sparse_categorical_accuracy: 0.8716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8604afc5f8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras also provides a convenient function to evaluate the performance on the independent test data we have retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 210us/sample - loss: 1.5312 - sparse_categorical_accuracy: 0.9300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5311651317596435, 0.93]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performance is about 94% on an independent test sample - which is ok for a first go.\n",
    "More complex models achieve more than 99% accuracy, a summary can be found on Yann LeCuns [MNIST page](http://yann.lecun.com/exdb/mnist/index.html)\n",
    "\n",
    "We can also make some predictions and look at the confustion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)\n",
    "y_hat = tf.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 972    2    1    0    0    0    2    2    1    0]\n",
      " [   0 1126    3    0    0    0    5    0    1    0]\n",
      " [  16   12  977    1    6    0    1   11    5    3]\n",
      " [  14    9   73  825    3   28    7   12   36    3]\n",
      " [   1    2    7    0  954    0    5    0    2   11]\n",
      " [   7    2    4    4    4  783   18    3   63    4]\n",
      " [  25    4    3    0    9    1  907    0    9    0]\n",
      " [   1    9   28    1    9    1    0  953    0   26]\n",
      " [  17   15   20    1   18    0    2   13  880    8]\n",
      " [  15   10    2    3   34    5    0    9    8  923]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test,y_hat)\n",
    "\n",
    "print(cm)\n",
    "\n",
    "# Show confusion matrix \n",
    "plt.matshow(cm, cmap='seismic')\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A More Complex Model\n",
    "\n",
    "We now create a more complex model by adding two convolutional layers and increase the number of nodes \n",
    "in the intermediate fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              3212288   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,274,634\n",
      "Trainable params: 3,274,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add((tf.keras.layers.Conv2D(filters=32, kernel_size=[5,5], padding='same', activation='relu',input_shape=(28,28,1 ))))\n",
    "model.add((tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2)))\n",
    "model.add((tf.keras.layers.Conv2D(filters=64, kernel_size=[5,5], padding='same', activation='relu' )))\n",
    "model.add((tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2)))\n",
    "model.add((tf.keras.layers.Flatten()))\n",
    "model.add((tf.keras.layers.Dense(1024, activation='relu')))\n",
    "model.add((tf.keras.layers.Dropout(0.5)))\n",
    "model.add((tf.keras.layers.Dense(10, activation='softmax')))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how this moderate increase in complexity increased the number of parameters from ca. 700,000 to more than 3 Million already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 141s 2ms/sample - loss: 2.3019 - sparse_categorical_accuracy: 0.1099\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 151s 3ms/sample - loss: 2.3013 - sparse_categorical_accuracy: 0.1124\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 147s 2ms/sample - loss: 2.3014 - sparse_categorical_accuracy: 0.1124\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 160s 3ms/sample - loss: 2.3013 - sparse_categorical_accuracy: 0.1124\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 145s 2ms/sample - loss: 2.3013 - sparse_categorical_accuracy: 0.1124\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 145s 2ms/sample - loss: 2.3014 - sparse_categorical_accuracy: 0.1124\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 166s 3ms/sample - loss: 2.3014 - sparse_categorical_accuracy: 0.1124\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 149s 2ms/sample - loss: 2.3014 - sparse_categorical_accuracy: 0.1124\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 149s 2ms/sample - loss: 2.3013 - sparse_categorical_accuracy: 0.1120\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 150s 2ms/sample - loss: 2.3013 - sparse_categorical_accuracy: 0.1124\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 6s 616us/sample - loss: 2.3011 - sparse_categorical_accuracy: 0.1135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.301110806274414, 0.1135]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()\n",
    "loss_values = history_dict['loss']\n",
    "acc_values = history_dict['sparse_categorical_accuracy']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "fig, axes = plt.subplots(2, sharex=True)\n",
    "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
    "axes[0].plot(loss_values)\n",
    "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
    "axes[1].set_xlabel(\"Iteration\", fontsize=14)\n",
    "axes[1].plot(acc_values)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
